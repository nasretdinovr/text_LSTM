{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from __future__ import print_function\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from model import TextGenerator \n",
    "from get_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preparing raw data\n",
    "filename = \"alice.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "seq_len = 50\n",
    "n_chars, n_vocab, n_examples, X, Y, int_to_char, char_to_int = get_data(raw_text, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextGenerator (\n",
      "  (lstm): LSTM(47, 512, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout (p = 0.5)\n",
      "  (scores): Linear (512 -> 47)\n",
      "  (batchnormD): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "H = 512 #hidden size\n",
    "D = n_vocab # features\n",
    "layers = 2 # number of lsmt layers\n",
    "B = 16 # batch size\n",
    "V = n_vocab # vocabulary size\n",
    "model = TextGenerator(D,H,layers,B,V)\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.08, momentum = 0.9, nesterov = True)\n",
    "print (model)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 Variable containing:\n",
      " 3.8975\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0 100 Variable containing:\n",
      " 3.1021\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0 200 Variable containing:\n",
      " 2.7777\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_iter = n_examples/B\n",
    "\n",
    "for epoch in range(1):\n",
    "    hidden = model.init_hidden(B)\n",
    "    for it in xrange(num_iter):\n",
    "        model.zero_grad()\n",
    "\n",
    "        start = np.random.randint(0, len(X)-2-B)\n",
    "        inp = prepeare_X(X[start:start+B],B,seq_len, n_vocab)\n",
    "        inp = inp.cuda() \n",
    "        \n",
    "        target = Y[start:start+B]\n",
    "        tensor1 = torch.LongTensor(target)\n",
    "        m = autograd.Variable(tensor1)\n",
    "        m = m.cuda()\n",
    "        \n",
    "        tag_scores, hidden = model(inp, hidden)\n",
    "        tag_scores = tag_scores.view(B*seq_len, -1)\n",
    "        m = m.view(B*seq_len)\n",
    "        loss = loss_function(tag_scores, m)\n",
    "        if ( it%100 == 0 ):\n",
    "            print (epoch, it , loss)\n",
    "        hidden[0].detach_()\n",
    "        hidden[1].detach_()\n",
    "        loss.backward(retain_variables=True)\n",
    "        optimizer.step()\n",
    "        target = Y[start+(epoch+1)]\n",
    "        pattern = X[start+(epoch+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = np.random.randint(0, len(X)-2)\n",
    "pattern = X[start]\n",
    "s = \"\"\n",
    "hidden = model.init_hidden(1)\n",
    "for it in xrange(1000):\n",
    "\n",
    "    inp = prepeare_X(pattern,1,seq_len, n_vocab)\n",
    "    scores, hidden = model.forward2(inp.cuda(), hidden) #for GPU\n",
    "    hidden[0].detach_()\n",
    "    hidden[1].detach_()\n",
    "#    scores, hidden = model.forward2(inp, hidden)\n",
    "    qwer, tmp = torch.max(scores,1)\n",
    "    final = np.squeeze(tmp.data.cpu().numpy()) #for GPU\n",
    "#    final = np.squeeze(tmp.data.numpy())\n",
    "    predicted_char = int_to_char[final[seq_len-1]]\n",
    "    pattern.append(final[seq_len-1])\n",
    "    pattern = pattern[1:]\n",
    "    s += predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uthe soull ce the wathe sout in the be the woull the be the wathe south the wall the wer the she the the she the the woull the the the sed the sout the the wall the the she the sout the she the the sed the the the sout the the se watling the sound the sed the the she the s and the she the found the sout fout the she fout the she the sound the the she fout and the waing the she fout on the waind the be the waling the wand the she fout on the wall the the wall the be the she fout nould the wall the sound the sound the the soull the sed the wall the the she the the the sout and the sout of the she the s mound the she the wand the she the s bot on the she found the sout of the the sout the she sound the the saing the she sould and the se the southe sou fout alice sout an the she and the sound alit allice and the wall the wall the se and the seat ou the she waing the she wall the fout on the seat on the sou the walit on the me the sout ou the was in the the the the wat the so the the wou th\n"
     ]
    }
   ],
   "source": [
    "print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
